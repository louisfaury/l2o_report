\chapter{Related work}
	{
		\label{chap::related}
		\section{Numerical optimization}
		{
			\paragraph{} The field of optimization has been studied for many years and for a great diversity of problems. Providing a complete review of the subject would be out of the scope of this paper, and therefore we provide only a short reminder on different approaches in the domain.  
	
	Some simple settings (convexity, $L$-smoothness, ..) have been intensively exploited to devise a large number of optimizers, derive upper-bound convergence rates (\cite{nemirovskii1983problem}) and even some information theoretical complexity lower bounds for black-box optimizers \cite{agarwal2009information}. More recently, motivated by the growing interest in deep learning, a lot of research efforts were also invested in devising smart, adaptative optimizers for complicated, very high dimensional objectives. Some of the most famous ones include AdaDelta \cite{zeiler2012adadelta}, RMSProp \cite{hinton2012rms} and Adam \cite{kingma2014adam}. Others authors focused on leveraging the particular structure of deep-learning architecture to efficiently compute, use curvature information and sometime overcome difficulties of curvature-based updates - \cite{vinyals2012krylov}, \cite{martens2010deep}, \cite{arjovsky2015saddle} are good examples of this trend. The general interest for deep learning also impulsed the rebirth of old methods that showed, after a few adaptations, promising results - \cite{hazan2016graduated}. 
	
	\paragraph{}Part of the diversity of existing optimizers is explained by the different type of oracles available for a given problem. Oracle-models are often considered in numerical optimization, for cases in which the literal expression of the function is unknown, or just too complicated to use. The optimization algorithm can only make queries to access a black-box like information $o_t$ of the function at time $t$. For a general function $f$ (possibly differentiable) mapping some multivariate parameter $\theta$ to $\mathbb{R}$, typical oracles involve zeroth-order oracle $o^0_t = \left[f(\theta_t)\right]$ and first order oracles $o^1_t = \left[f(\theta_t),\partial f(\theta_t)\right]$ with $\partial f$ denoting the sub-gradient operator of $f$. It is also common to consider noisy version of those oracles - for instance $\hat{o}_0^t = \left[f(\theta_t)+\xi\right]$ with $\xi$ a random variable, usually with finite first and second moments. The case of noisy first order oracles has been widely adopted in the machine learning community and led to many innovations (a detailed survey can be found in \cite{bottou2016optimization}). Noisy zeroth order oracles also received a lot of attention from the bandit community \cite{agarwal2011stochastic}, the Bayesian optimization community \cite{shahriari2016taking} and the evolutionary optimization communities (for which one of the most successful method being Covariance Matrix Adaptation Evolutionary Strategy \cite{hansen2016cma}). It have also seen a few heuristics approaches (the Nelder-Mead heuristic \cite{nelder1965simplex} being one of them). 
		}
		
		\section{Meta-learning}
		{
			\paragraph{} Learning to learn (or meta-learning) is not a recent idea. \cite{schmidhuber1987} thought of a Recurrent Neural Network (RNN) able to modify its own weights, building a fully differentiable system allowing the training to be learned by gradient descent. \cite{hochl2l} proposed to discover optimizers by gradient descent, optimizing RNNs modeling the optimization sequence with a learning signal emerging from backpropagation on a first network. 
	
	Recently, some meta-learning tentatives have shown great progress in different optimization fields. Various attempt tried to dynamically adapt the hyper-parameters of hand-designed algorithms, like \cite{daniel2016learning} or \cite{hansen2016using}. Using gradient statistics as an input for a recurrent neural net, \cite{li2017learning} were able to reinforcement learn a policy effective for training deep neural networks. In \cite{andrychowicz2016learning}, the authors show that when leveraging first-order information one could learn by gradient-descent optimizers that outperforms current state-of-the-art of existing problems - however only when the meta-train dataset is made of the same class of problem. When confronted to a different class of functions, the meta-learner is unable to infer efficient optimization moves. With the same idea of using gradient-descent for training the optimizer, \cite{chen2017learning} use zeroth order information in order to learn an optimizer for the Bayesian optimization setting.  

	\paragraph{} One could think that by showing enough examples to a meta-learner (namely made up of instances where traditional optimizers reach their limits), and adapting its structure to cover a large number of classes of functions, it could adapt to unknown loss landscapes. This idea was exploited by \cite{wil2l}, who manage to learn optimizers that generalizes to completely unseen data, while still being able to scale up to high-dimensional problems. Their process namely involves training by gradient descent hierarchical RNNs and showing it a great variety of examples. However, their optimizer's structure remains quite complicated, and doesn't provide human-level understanding of the features leveraged by the meta-learner. We believe that a more intelligible architecture could enable us to understand better what the network is learning, while still being effective on a large class of functions, when trained on a selected number of meta-examples. 
	
	\paragraph{}We also want to point out that if most of the method cited above call themselves meta-learning or learning to learn, they are closer to a \emph{learning to optimize} procedure. Indeed, none of their rewards or meta-loss are based on a validation or test loss, but on training loss. Shifting this paradigm tower learning to learn could reveal useful to investigate some current hot research topic on generalization in complex models - see \cite{keskar2016large} and \cite{dinh2017sharp}. However, to do so, the architecture and behavior of the meta learner have to be human-interpretable. Some recent works on meta-learning (\cite{ravi2016optimization} for instance) are closer to that problematic in the sense that they aim at learning good representations of \emph{what to learn} over whole datasets, that can be used later for \emph{few-shot learning}. 
	Recently, \cite{franceschi2017bridge} bridged the two domains of meta-learning and hyper-parameter optimisation. Therefore, work such as \cite{maclaurin2015gradient} can also be understood as meta-learning. This also opens a whole new exciting field of research, where the meta-learner is just seen as a complex model of hyper-parameters that needs to be optimized in some novel ways. 
		}
	}
