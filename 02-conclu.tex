\chapter{Conclusion}
	{
		
		\paragraph{} In this report, we presented a framework for learning to optimize that build towards meta-generalization. By proposing to pose the problem as a navigation problem in high dimensional loss landscapes, using tools from reinforcement learning and supervised learning and providing a small but sufficient set of prototypical landscape that often arise in optimization problem, we learned an optimization algorithm that shows good behavior on a diverse class of held-out functions. 
		
		We provide some good results on a benchmark of hard two-dimensional functions, and we extend our approach to obtain some promising results in higher-dimensions - we give examples on a linear binary classification task and a shallow neural network multi-class loss. The results of this work will be published as a conference paper at LION 12 (LION: Learning and Intelligent Optimization) in June 2018. 
		
		We provide some ideas for future work, that will be tackled during a PhD starting shortly after this master thesis. 
		
		\paragraph{} I wish to thank Flavian Vasile, my supervisor at Criteo. It was a real pleasure working under his guidance for six months. I also wish to thank the whole Criteo research team, and especially Hadrien Hendrikx and Ugo Tanielian for all the interesting discussions we had while working together on each others current interests. 
	}